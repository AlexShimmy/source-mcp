<div align="center">
  <h1>üîç Source-MCP</h1>
  <p><strong>A Model Context Protocol (MCP) server for semantic search and Retrieval-Augmented Generation (RAG) over local codebases and documents.</strong></p>
</div>

---

## üìñ Overview

**Source-MCP** leverages the [Model Context Protocol](https://github.com/anthropic/modelcontextprotocol) to provide AI assistants (like Claude, Gemini, and others) with direct access to local files through semantic search.

Instead of manually copy-pasting code or documentation into your prompts, Source-MCP automatically indexes your local repository, generates vector embeddings, and enables the AI to semantically search and retrieve only the most relevant files.

## ‚ú® Key Features

- **Dual Embedding Support:**
  - **OpenAI:** Uses robust `text-embedding-3-small` (1536 dimensions) for high-quality enterprise embeddings.
  - **FastEmbed (Local):** Uses `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2` (384 dims). Runs entirely locally, no API keys required, and supports multilingual inquiries.
- **Smart Incremental Indexing:** Uses file fingerprints (modified time + size) to only index new or modified files, ensuring lightning-fast startup times.
- **Auto-Migration:** Automatically detects embedding dimension changes (e.g., switching from OpenAI to FastEmbed) and safely recreates the vector index.
- **Web Dashboard (Port 8000):**
  - **Live Logs:** View real-time indexing and search activity with auto-scroll.
  - **Reindex Base:** Force-wipe the vector DB and manifest for a completely fresh full scan.
  - **Reindex Base:** Force-wipe the vector DB and manifest for a completely fresh full scan.
  - **Search Debugging:** Special endpoint (`/api/search/debug?q=...`) to test raw semantic search scores.

## ü§î Why local embeddings and `zvec`?

We use [**zvec**](https://github.com/alibaba/zvec), a lightweight, high-performance vector database maintained by Alibaba. `zvec` is embedded directly into the Python process, eliminating the need to set up or run external vector servers (like Pinecone, Milvus, or Qdrant). Combined with `FastEmbed`, this allows Source-MCP to build the entire semantic search pipeline **fully offline**, quickly, and entirely on your local machine.

## üöÄ Installation & Setup

1. **Prerequisites:** Ensure you have Python 3.10+ and [`uv`](https://github.com/astral-sh/uv) installed.
2. **Clone the repository:**

   ```bash
   git clone https://github.com/your-username/source-mcp.git
   cd source-mcp
   ```

3. **Install Dependencies:**

   ```bash
   # uv will automatically handle virtual environment creation and dependencies
   uv sync
   ```

## ‚öôÔ∏è Configuration

Create a `.env` file in the root directory (you can copy `.env.example` if available).

```bash
# Choose your provider: "openai" or "fastembed"
EMBEDDING_PROVIDER=openai

# Required ONLY if using OpenAI
# Required ONLY if using OpenAI
OPENAI_API_KEY=sk-your-openai-api-key

# Optional: Path to store the vector database (Defaults to `.source-mcp/zvec_db` in the index dir)
ZVEC_PATH=./zvec_db

# Optional: Which directory to index (Defaults to current directory)
SOURCE_MCP_INDEX_DIR=/path/to/your/project

# Optional: Port for the Web Dashboard (Defaults to 8000)
WEB_PORT=8000
```

## üñ±Ô∏è Usage

### Running Manually (Terminal & Dashboard)

To start the MCP server manually and access the web dashboard:

```bash
uv run python -m src.main --path .
```

- The **MCP protocol** will listen on `stdio`.
- The **Web Dashboard** will be available at [http://localhost:8000](http://localhost:8000).

```json
{
  "mcpServers": {
    "source-mcp": {
      "command": "uv",
      "args": [
        "--directory",
        "/absolute/path/to/source-mcp",
        "run",
        "python",
        "-m",
        "src.main"
      ]
    }
  }
}
```

–í—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (—Ç–∞–∫–∏–µ –∫–∞–∫ `SOURCE_MCP_INDEX_DIR`, `EMBEDDING_PROVIDER` –∏–ª–∏ `OPENAI_API_KEY`) —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∑–∞–¥–∞–≤–∞—Ç—å —á–µ—Ä–µ–∑ —Ñ–∞–π–ª `.env` –≤ –∫–æ—Ä–Ω–µ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ Source-MCP.

### üíª Using with Cursor IDE

Cursor –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–∫—É —Å–µ—Ä–≤–µ—Ä–æ–≤ MCP —Å –ø–æ–º–æ—â—å—é –≥–ª—É–±–æ–∫–∏—Ö —Å—Å—ã–ª–æ–∫. –ù–∞–∂–º–∏—Ç–µ –Ω–∞ –∫–Ω–æ–ø–∫—É –Ω–∏–∂–µ, —á—Ç–æ–±—ã –¥–æ–±–∞–≤–∏—Ç—å Source-MCP (–æ–±–Ω–æ–≤–∏—Ç–µ –ø—É—Ç–∏ –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º):

[![Add to Cursor](https://img.shields.io/badge/Add%20to%20Cursor-black?style=for-the-badge&logo=cursor&logoColor=white)](cursor://mcp?name=Source-MCP&command=uv%20--directory%20/absolute/path/to/source-mcp%20run%20python%20-m%20src.main)

–í –∫–∞—á–µ—Å—Ç–≤–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã, –≤—ã –º–æ–∂–µ—Ç–µ –¥–æ–±–∞–≤–∏—Ç—å —Å–ª–µ–¥—É—é—â–∏–π —Å–æ–∫—Ä–∞—â–µ–Ω–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥ –≤—Ä—É—á–Ω—É—é –≤ `Cursor Settings` > `Features` > `MCP`:

- **Name:** `Source-MCP`
- **Type:** `command`
- **Command:** `uv --directory /absolute/path/to/source-mcp run python -m src.main`

### üíª Using with VS Code (Roo Code / Cline)

–î–æ–±–∞–≤—å—Ç–µ —Å–ª–µ–¥—É—é—â—É—é –∑–∞–ø–∏—Å—å –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤–∞—à–µ–≥–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è (`cline_mcp_settings.json`), –∞ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ –≤ —Ñ–∞–π–ª–µ `.env` –ø—Ä–æ–µ–∫—Ç–∞:

```json
{
  "mcpServers": {
    "source-mcp": {
      "command": "uv",
      "args": [
        "--directory",
        "/absolute/path/to/source-mcp",
        "run",
        "python",
        "-m",
        "src.main"
      ]
    }
  }
}
```

## üß™ Testing

The project uses `pytest` for unit and end-to-end tests. To run the test suite:

```bash
uv run python -m pytest tests/ -v
```

## üìú License

This project is licensed under the MIT License - see the LICENSE file for details.
